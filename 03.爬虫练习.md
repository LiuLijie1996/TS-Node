## 初始化项目

```
npm init -y   初始化项目
tsc --init    生成ts配置文件
```



## 下载依赖包

```
npm install superagent jsdom --save
```



## 爬虫类

```ts
import superagent from "superagent";
import { JSDOM } from "jsdom";
import fs from "fs";
import path from "path";

// 新闻类型
interface NewsItem {
  title: string; //标题
  link: string; //链接
  heat_score: number; //热度
}

// 得到所有新闻后整理出的新闻类型
interface NewsResult {
  time: number; //时间
  data: NewsItem[];//新闻列表
}

// 存到文件中的数据结构
interface Content {
  [propName: number]: NewsItem[];
}

// 爬虫类
class Crowller {
  //私有属性
  private filePath = path.resolve(__dirname, "../data/newsList.json");
  private url = "http://www.baidu.com/"; //目标地址

  // 构造函数
  constructor() {
    this.initSpiderProcess();
  }

  //负责爬虫的流程
  async initSpiderProcess() {
    // 1.获取html的内容
    const html = await this.getRawHtml();
    // 2.分析html内容，得到最终的数据
    const newsResult: NewsResult = this.getHtmlInfo(html);
    // 3.生成要存储的内容
    const fileContent = this.getJsonContent(newsResult);
    // 4.存储内容
    this.saveJsonData(JSON.stringify(fileContent));
  }

  // 获取html的内容
  async getRawHtml() {
    // 请求数据
    let result = await superagent.get(this.url);
    return result.text; //返回html内容
  }

  // 解析html内容
  getHtmlInfo(html: string) {
    let document = new JSDOM(html).window.document;
    let innerHTML = document.querySelector("#hotsearch_data")?.innerHTML;
    let dataList = innerHTML && JSON.parse(innerHTML).hotsearch; //解析数据
    let NewsList: NewsItem[] = [];
    // 整理数据
    dataList.forEach((item: any) => {
      let newItem: NewsItem = {
        title: item.pure_title,
        link: decodeURIComponent(item.linkurl),
        heat_score: item.heat_score,
      };
      NewsList.push(newItem);
    });

    // 返回最终的数据
    return {
      time: new Date().getTime(),
      data: NewsList,
    };
  }

  //生成要存储的内容
  getJsonContent(data: NewsResult) {
    let fileContent: Content = {};

    // 判断json文件是否存在
    if (fs.existsSync(this.filePath)) {
      // 存在，读取文件中的数据
      let readFile = fs.readFileSync(this.filePath, "utf-8") || "{}";
      fileContent = JSON.parse(readFile);
    }
    // 增加新内容
    fileContent[data.time] = data.data;

    // 返回全新内容
    return fileContent;
  }

  // 存储内容
  saveJsonData(content: string) {
    // 存到文件中
    fs.writeFileSync(this.filePath, content);
    console.log("存储完成");
  }
}

const crowller = new Crowller();
```



## 使用组合模式与单例模式优化代码

### 爬虫类

```ts
import superagent from "superagent";
import fs from "fs";
import path from "path";
import NewsAnalyzer from "./dellAnalyzer";

// 定义分析器的类型
export interface Analyzer {
  analyze: (html: string, filePath: string) => string;
}

// 爬虫类
class Crowller {
  //私有属性
  private filePath = path.resolve(__dirname, "../data/newsList.json");

  // 构造函数
  constructor(private analyzer: Analyzer, private url: string) {
    // 负责爬虫的流程
    this.initSpiderProcess();
  }

  //负责爬虫的流程
  private async initSpiderProcess() {
    // 1.获取html的内容
    const html = await this.getRawHtml();
    // 2.分析html，得到存储的数据
    const fileContent = this.analyzer.analyze(html, this.filePath);
    // 3.存储内容
    this.saveJsonData(fileContent);
  }

  // 获取html的内容
  private async getRawHtml() {
    // 请求数据
    let result = await superagent.get(this.url);
    return result.text; //返回html内容
  }

  // 存储内容
  private saveJsonData(content: string) {
    // 存到文件中
    fs.writeFileSync(this.filePath, content);
    console.log("存储完成");
  }
}

const url = "http://www.baidu.com/"; //目标地址
const analyzer = NewsAnalyzer.getInstance(); //实例化新闻分析类
new Crowller(analyzer, url);
```



### 新闻分析类

```ts
import { JSDOM } from "jsdom";
import fs from "fs";
import { Analyzer } from "./crowller";

// 新闻类型
interface NewsItem {
  title: string; //标题
  link: string; //链接
  heat_score: number; //热度
}

// 得到所有新闻后整理出的新闻类型
interface NewsResult {
  time: number; //时间
  data: NewsItem[];
}

// 存到文件中的数据结构
interface Content {
  [propName: number]: NewsItem[];
}

// 分析器类
export default class NewsAnalyzer implements Analyzer {
  static instance: NewsAnalyzer;

  // 将构造函数改成私有方法,这样在外部就不能实例化了
  private constructor() {}

  static getInstance() {
    // 判断instance是否被赋值当前类的实例
    if (!NewsAnalyzer.instance) {
      NewsAnalyzer.instance = new NewsAnalyzer();
    }

    // 返回当前类的实例
    return NewsAnalyzer.instance;
  }

  // 分析
  analyze(html: string, filePath: string) {
    // 1.分析html内容，得到最终的数据
    const newsResult: NewsResult = this.getHtmlInfo(html);
    // 2.生成要存储的内容
    const fileContent = this.getJsonContent(newsResult, filePath);
    return JSON.stringify(fileContent);
  }

  // 解析html内容
  private getHtmlInfo(html: string) {
    let document = new JSDOM(html).window.document;
    let innerHTML = document.querySelector("#hotsearch_data")?.innerHTML;
    let dataList = innerHTML && JSON.parse(innerHTML).hotsearch; //解析数据
    let NewsList: NewsItem[] = [];
    // 整理数据
    dataList.forEach((item: any) => {
      let newItem: NewsItem = {
        title: item.pure_title,
        link: decodeURIComponent(item.linkurl),
        heat_score: item.heat_score,
      };
      NewsList.push(newItem);
    });

    // 返回最终的数据
    return {
      time: new Date().getTime(),
      data: NewsList,
    };
  }

  //生成要存储的内容
  private getJsonContent(data: NewsResult, filePath: string) {
    let fileContent: Content = {};

    // 判断json文件是否存在
    if (fs.existsSync(filePath)) {
      // 存在，读取文件中的数据
      let readFile = fs.readFileSync(filePath, "utf-8") || "{}";
      fileContent = JSON.parse(readFile);
    }
    // 增加新内容
    fileContent[data.time] = data.data;

    // 返回全新内容
    return fileContent;
  }
}
```



注：使用组合模式的优点，如果下次爬取的是另外一个网站时，只需要重新建立一个分析器类进行分析数据，爬虫类则不需要在进行改动